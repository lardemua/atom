#!/usr/bin/env python

# stdlib
import matplotlib
import os

import atom_core.config_io
import atom_core.drawing
import sys
import argparse
import subprocess

from copy import deepcopy
from datetime import date, datetime

# 3rd-party
import yaml
import numpy
import rospy
import rospkg
import rosbag
import jinja2
import matplotlib.pyplot as plt
import networkx as nx

from colorama import Style, Fore

from graphviz import Digraph
from urdf_parser_py.urdf import URDF
from matplotlib import cm
from jinja2 import Environment, FileSystemLoader

# local packages
import atom_core.utilities as utilities

if __name__ == "__main__":
    # Parse command line arguments
    ap = argparse.ArgumentParser()
    ap.add_argument("-n", "--name", help='package name', type=str, required=True)
    ap.add_argument("-utf", "--use_tfs", action="store_true",
                    help='Use transformations in the bag file instead of generating new tfs from the xacro, '
                         'joint_state_msgs and robot state publisher.')
    args = vars(ap.parse_args())

    # --------------------------------------------------------------------------
    # Initial setup
    # --------------------------------------------------------------------------
    package_name = os.path.basename(args['name'])
    rospack = rospkg.RosPack()
    atom_calibration_path = rospack.get_path('atom_calibration')

    # Check if package is under $ROS_PACKAGE_PATH, abort if not
    assert (package_name in rospack.list()), \
        Fore.YELLOW + package_name + ' not found under ROS. Are you sure the path you gave in under your ' \
                                     '$ROS_PACKAGE_PATH? Calibration package will not work if it is not under the ' \
                                     '$ROS_PACKAGE_PATH. Please fix this before running the package configuration. ' \
        + Style.RESET_ALL

    package_path = rospack.get_path(package_name)  # full path to the package, including its name.
    package_base_path = os.path.dirname(package_path)  # parent path where the package is located

    rviz_file_template = atom_calibration_path + '/templates/config.rviz'
    rviz_set_initial_estimate = 'set_initial_estimate.rviz'
    rviz_collect_data = 'collect_data.rviz'
    rviz_calibrate = 'calibrate.rviz'
    set_initial_estimate_launch_file = package_path + '/launch/set_initial_estimate.launch'
    data_collection_launch_file = package_path + '/launch/collect_data.launch'
    calibrate_launch_file = package_path + '/launch/calibrate.launch'

    # Template engine setup
    file_loader = FileSystemLoader(atom_calibration_path + '/templates')
    env = Environment(loader=file_loader, undefined=jinja2.StrictUndefined)
    env.add_extension('jinja2.ext.do')

    # Date
    dt_string = datetime.now().strftime("%d/%m/%Y %H:%M:%S")

    # --------------------------------------------------------------------------
    # Read the config.yml file
    # --------------------------------------------------------------------------
    config_file = package_path + '/calibration/config.yml'
    print('Loading config file ' + config_file)
    config = atom_core.config_io.loadConfig(config_file)

    # Sensors colormap. Access with:  color_map_sensors[idx, :]
    cm_sensors = cm.Set3(numpy.linspace(0, 1, len(config['sensors'].keys())))

    # --------------------------------------------------------------------------
    # Setup the description file
    # --------------------------------------------------------------------------
    description_file, _, _ = atom_core.config_io.uriReader(config['description_file'])
    description_file_out_initial_estimate = package_path + '/urdf/initial_estimate.urdf.xacro'
    atom_core.config_io.execute('cp ' + description_file + ' ' + description_file_out_initial_estimate,
                                verbose=False)  # Copy the xacro to the initial_estimate file

    # --------------------------------------------------------------------------
    # Read the bag file
    # --------------------------------------------------------------------------
    bag_file, _, bag_file_rel = atom_core.config_io.uriReader(config['bag_file'])
    print('Loading bagfile ' + bag_file)
    bag = rosbag.Bag(bag_file)
    bag_info = bag.get_type_and_topic_info()
    bag_types = bag_info[0]
    bag_topics = bag_info[1]
    # print('\n' + str(bag_topics))

    # for topic, msg, t in bag.read_messages(topics=['chatter', 'numbers']):
    #     print(msg)
    bag.close()

    # --------------------------------------------------------------------------
    # Read the description.urdf.xacro file
    # --------------------------------------------------------------------------
    # Check the description file
    urdf_file = '/tmp/description.urdf'
    if os.path.exists(urdf_file):
        print('Deleting temporary file ' + urdf_file)
        os.remove(urdf_file)

    print('Parsing description file ' + description_file)
    atom_core.config_io.execute('xacro ' + description_file + ' -o ' + urdf_file, verbose=True)  # create tmp urdf file
    try:
        description = URDF.from_xml_file(urdf_file)  # read the urdf file
    except:
        atom_core.config_io.execute('xacro ' + description_file + ' -o ' + urdf_file,
                                    verbose=True)  # print xacro parsing
        raise ValueError('Could not parse description file ' + description_file)

    # --------------------------------------------------------------------------
    # Create a tf graph to support verifications
    # --------------------------------------------------------------------------
    if not args['use_tfs']:  # create a graph using the information in the urdf
        print('Creating transformation tree using the urdf robot description ...')
        gx = nx.DiGraph()

        for link in description.links:  # A graph node for each link in the urdf
            gx.add_node(link.name)
            print(link.name)

        for joint in description.joints:  # atomic transformations are given by the joints
            if joint.type == 'fixed':
                gx.add_edge(joint.parent, joint.child, weight=1, type='static')
            else:
                gx.add_edge(joint.parent, joint.child, weight=1, type='dynamic')
    else:
        print('Creating transformation tree using the tfs in the bagfile ...')
        gx = nx.DiGraph()

        print('Loading bagfile ' + bag_file)
        bag = rosbag.Bag(bag_file)

        for topic, msg, t in bag.read_messages(topics=['/tf']):
            for transform in msg.transforms:
                if not gx.has_edge(transform.header.frame_id, transform.child_frame_id):
                    gx.add_edge(transform.header.frame_id, transform.child_frame_id, weight=1, type='dynamic')

        for topic, msg, t in bag.read_messages(topics=['/tf_static']):
            for transform in msg.transforms:
                if not gx.has_edge(transform.header.frame_id, transform.child_frame_id):
                    gx.add_edge(transform.header.frame_id, transform.child_frame_id, weight=1, type='static')

        bag.close()
        # nx.draw(gx, with_labels=True)
        # plt.show()

    # --------------------------------------------------------------------------
    # Verifications: Run as much as we can think of to see if something is wrong. Better early than late.
    # --------------------------------------------------------------------------
    print('Running verifications ... please wait ...')

    compressed_topics = {}  # a list of compressed topics to decompress in the launch file
    # Check if config sensor topics exist in the bag file
    for sensor_key in config['sensors']:
        topic = config['sensors'][sensor_key]['topic_name']
        if topic not in bag_topics:

            topic_compressed = topic + '/compressed'
            if topic_compressed in bag_topics:  # Check if the topic is a compressed image topic
                msg_type = bag_info[1][topic_compressed].msg_type
                if msg_type == 'sensor_msgs/CompressedImage':  # Check if the topic of correct msg_type
                    compressed_topics[topic] = {'topic_compressed': topic_compressed, 'msg_type': msg_type,
                                                'sensor_key': sensor_key}
                    print(Fore.BLUE + 'Topic ' + topic + ' is in compressed format (' + topic_compressed +
                          '). Will setup a decompressor.' + Style.RESET_ALL)
                else:
                    raise ValueError(Fore.RED + ' Topic ' + topic + ' (from sensor ' + sensor_key +
                                     ') exists in compressed format in the bag file, but is not of msg_type '
                                     '"sensor_msgs/CompressedImage"' + Style.RESET_ALL)
            else:

                raise ValueError(Fore.RED + ' Topic ' + topic + ' (from sensor ' + sensor_key +
                                 ') does not exist in the bag file.' + Style.RESET_ALL)

    throttle_topics = {}
    use_throttle_topics = {}
    for sensor_key in config['sensors']:
        topic = config['sensors'][sensor_key]['topic_name']
        topic_compressed = topic + '/compressed'
        if topic_compressed in bag_topics:  # Check if the topic is a compressed image topic
            topic = topic_compressed
        if 'throttle' in config['sensors'][sensor_key]:
            throttle = config['sensors'][sensor_key]['throttle']
            print('Sensor ' + sensor_key + ' has throttle')

            use_throttle = True
        else:
            print('Sensor ' + sensor_key + ' does not have throttle')
            throttle = None
            use_throttle = False
        # else:

        throttle_topics[topic] = {'throttled_topic': topic, 'sensor_key': sensor_key, 'use_throttle': use_throttle,
                                  'throttle_hz': throttle}

    # Verify consistency of the tf tree
    frames_to_verify = {'world_link': config['world_link'],
                        'calibration_pattern.pattern_link': config['calibration_pattern']['parent_link']}
    for sensor_key in config['sensors']:  # Check if link, child_link and parent_link exist in the bagfile.
        for frame in ['child_link', 'parent_link', 'link']:
            frames_to_verify[sensor_key + '.' + frame] = config['sensors'][sensor_key][frame]

    print('Checking if all tf frames exist ...')
    print(frames_to_verify)
    for key, frame in frames_to_verify.items():
        if not frame in gx:
            raise ValueError('Error: frame ' + Fore.RED + frame + Style.RESET_ALL + ' given in config file for ' +
                             Fore.BLUE + key + Style.RESET_ALL + ' does not exist. Check config file ' +
                             Fore.BLUE + config_file + Style.RESET_ALL)

    # if nx.is_connected(gx):
    if nx.is_weakly_connected(gx):
        print('TF tree is connected.')
    else:
        pos = nx.random_layout(gx)
        edges, weights = zip(*nx.get_edge_attributes(gx, 'weight').items())
        edge_labels = nx.draw_networkx_edge_labels(gx, pos)
        nx.draw(gx, with_labels=True)
        plt.show()
        raise ValueError('TF tree is not connected. Aborting.')

    # Pretty print of transformation chains
    # TODO How to detect a dynamic transformation using the information in the bagfile's tfs?
    print(
        'Transformations for sensors. Color coding is ' + Fore.RED + 'root link' + Fore.RESET + ', ' + Fore.BLUE + 'to be calibrated'
        + Fore.RESET + ', ' + Fore.GREEN + 'dynamic transformation' + Fore.RESET + ', ' + Fore.LIGHTMAGENTA_EX +
        'sensor data frame' + Fore.RESET + '.')
    for sensor_key, sensor in config['sensors'].items():
        paths = nx.shortest_path(gx, config['world_link'], sensor['link'])  # path between root and sensor data frame
        print('Path from ' + Fore.RED + config['world_link'] + Fore.RESET + ' to sensor ' + Fore.LIGHTMAGENTA_EX +
              sensor_key + Fore.RESET + ':')
        s = '['
        for path in paths:
            if path == config['world_link']:
                s += Fore.RED + path + Fore.RESET + ', '
            elif path == sensor['parent_link'] or path == sensor['child_link']:
                s += Fore.BLUE + path + Fore.RESET + ', '
            elif path == sensor['link']:
                s += Fore.LIGHTMAGENTA_EX + path + Fore.RESET + ', '
            else:
                for joint in description.joints:  # atomic transformations are given by the joints
                    if path == joint.parent or path == joint.child:
                        if joint.type == 'fixed':
                            s += path + ', '
                        else:
                            s += Fore.GREEN + path + Fore.RESET + ', '
                        break
        s = s[:-2]
        s += ']'
        print(s)

    # --------------------------------------------------------------------------
    # Create dot calibration graph (used for printing out a summary)
    # --------------------------------------------------------------------------
    g = Digraph('G', filename='summary', directory='/tmp/', graph_attr={'title': 'graph'})  # create a graph

    for link in gx.nodes:  # A graph node for each link in the urdf
        rgb = matplotlib.colors.rgb2hex([0, 0, 0])  # black by default
        label = link
        if config['world_link'] == link:
            label += '\n(world link)'
            rgb = matplotlib.colors.rgb2hex([1, 0, 0])

        for sensor_key, sensor in config['sensors'].items():
            if sensor['link'] == link:
                label += '\n(data from sensor ' + sensor_key + ')'
                rgb = matplotlib.colors.rgb2hex([0, 0.5, 0])

        g.node(link, label=label, _attributes={'penwidth': '2', 'color': rgb}, )

    for parent, child, edge_data in gx.edges(data=True):  # atomic transformations are given by the joints
        label = ''
        type = edge_data['type']
        rgb = matplotlib.colors.rgb2hex([0, 0, 0])  # black by default
        for sensor_key, sensor in config['sensors'].items():  # if the joint is marked for calibration
            if sensor['parent_link'] == parent and sensor['child_link'] == child:
                label += 'To be calibrated\n'
                rgb = matplotlib.colors.rgb2hex([0, 0, 1])

        label += type

        g.edge(parent, child, color=rgb, style='solid', _attributes={'penwidth': '1', 'fontcolor': rgb},
               label=label)

    # g.view()
    g.render(filename='summary', directory=package_path + '/calibration', cleanup=True)

    # --------------------------------------------------------------------------
    # Create the playback launch file
    # --------------------------------------------------------------------------
    playbag_launch_file = package_path + '/launch/playbag.launch'
    print('Setting up ' + playbag_launch_file + ' ...')

    template = env.get_template('playbag.launch')
    with open(playbag_launch_file, 'wb') as f:
        output = template.render(c={'filename': os.path.basename(playbag_launch_file),
                                    'date': dt_string,
                                    'bag_file': bag_file_rel,
                                    'use_tfs': args['use_tfs'],
                                    'package_name': package_name,
                                    'rviz_set_initial_estimate': rviz_set_initial_estimate,
                                    'use_compressed_topics': bool(compressed_topics),
                                    'compressed_topics': compressed_topics,
                                    'throttle_topics': throttle_topics
                                    })
        f.write(output.encode('utf-8'))

    # --------------------------------------------------------------------------
    # Create the set_initial_estimate launch file
    # --------------------------------------------------------------------------
    launch_file = set_initial_estimate_launch_file
    print('Setting up ' + launch_file + ' ...')

    template = env.get_template(os.path.basename(launch_file))
    with open(launch_file, 'wb') as f:
        output = template.render(c={'filename': os.path.basename(launch_file),
                                    'date': dt_string,
                                    'package_name': package_name,
                                    'rviz_set_initial_estimate': rviz_set_initial_estimate,
                                    'bag_file': bag_file_rel,
                                    'marker_size': 0.5
                                    })
        f.write(output.encode('utf-8'))

    # --------------------------------------------------------------------------
    # Create the data collection launch file
    # --------------------------------------------------------------------------
    launch_file = data_collection_launch_file
    print('Setting up ' + launch_file + ' ...')

    template = env.get_template(os.path.basename(launch_file))
    with open(launch_file, 'wb') as f:
        output = template.render(c={'filename': os.path.basename(launch_file),
                                    'date': dt_string,
                                    'package_name': package_name,
                                    'rviz_collect_data': rviz_collect_data,
                                    'bag_file': bag_file_rel
                                    })
        f.write(output.encode('utf-8'))

    # --------------------------------------------------------------------------
    # Create the calibrate launch file
    # --------------------------------------------------------------------------
    launch_file = calibrate_launch_file
    print('Setting up ' + launch_file + ' ...')

    template = env.get_template(os.path.basename(launch_file))
    with open(launch_file, 'wb') as f:
        output = template.render(c={'filename': os.path.basename(launch_file),
                                    'date': dt_string,
                                    'package_name': package_name,
                                    'rviz_calibrate': rviz_calibrate
                                    })
        f.write(output.encode('utf-8'))

    # --------------------------------------------------------------------------
    # Check if sensor_ids are properly created
    # --------------------------------------------------------------------------
    for sensor_key in config['sensors']:
        topic = config['sensors'][sensor_key]['topic_name']
        topic_compressed = topic + '/compressed'
        if topic in bag_topics:
            msg_type = bag_info[1][topic].msg_type
        elif topic_compressed in bag_topics:
            msg_type = bag_info[1][topic_compressed].msg_type
        if ('sensor_id' not in config['sensors'][sensor_key]) or (
                config['sensors'][sensor_key]['sensor_id'] not in ['rgb', 'depth', 'lidar', 'laserscan']):
            print(
                Fore.YELLOW + 'Warning: Sensor ID not properly identified for sensor ' + sensor_key + ' with topic '
                + topic + "Sensor will be identified by message type."+ Style.RESET_ALL)
            if msg_type == 'sensor_msgs/CompressedImage' or \
                    msg_type == 'sensor_msgs/Image':
                config['sensors'][sensor_key]['sensor_id'] = 'rgb'
            elif msg_type == 'sensor_msgs/LaserScan':
                config['sensors'][sensor_key]['sensor_id'] = 'laserscan'
            elif msg_type == 'sensor_msgs/PointCloud2':
                config['sensors'][sensor_key]['sensor_id'] = 'lidar'
            else:
                raise ValueError(Fore.RED +  'Error: Cannot generate rviz configuration for sensor ' + sensor_key + ' with topic '
                    + topic + Style.RESET_ALL)


    # --------------------------------------------------------------------------
    # Create the rviz config core displays (used in several rviz config files)
    # --------------------------------------------------------------------------
    # TODO change rviz fixed_frame according to args['world_link']
    core_displays = []

    # Create grid, tf and robot model displays
    rendered = env.get_template('/rviz/Grid.rviz').render(c={'Reference_Frame': config['world_link']})
    core_displays.append(yaml.load(rendered, Loader=yaml.SafeLoader))

    rendered = env.get_template('/rviz/TF.rviz').render(c={'Name': 'TF'})
    core_displays.append(yaml.load(rendered, Loader=yaml.SafeLoader))

    rendered = env.get_template('/rviz/RobotModel.rviz').render(c={'Name': 'RobotModel'})
    core_displays.append(yaml.load(rendered, Loader=yaml.SafeLoader))

    # --------------------------------------------------------------------------
    # Create the rviz config file for the set_initial_estimate
    # --------------------------------------------------------------------------
    print('Setting up ' + rviz_set_initial_estimate + ' ...')
    rviz = yaml.load(open(rviz_file_template), Loader=yaml.SafeLoader)
    rviz['Visualization Manager']['Global Options']['Fixed Frame'] = config[
        'world_link']  # set fixed frame to world_link
    displays = deepcopy(core_displays)  # start with the core displays

    # Create interactive marker display for moving the sensors
    rendered = env.get_template('/rviz/InteractiveMarker.rviz').render(c={'Name': 'MoveSensors-InteractiveMarker',
                                                                          'Update_Topic': 'set_initial_estimate/update'}
                                                                       )
    displays.append(yaml.load(rendered, Loader=yaml.SafeLoader))

    # Generate rviz displays according to the sensor types
    for idx, sensor_key in enumerate(config['sensors']):
        color = atom_core.drawing.colormapToRVizColor(cm_sensors[idx, :])
        topic = config['sensors'][sensor_key]['topic_name']
        topic_compressed = topic + '/compressed'
        # if topic in bag_topics:
        #     msg_type = bag_info[1][topic].msg_type
        # else:
        #     msg_type = bag_info[1][topic_compressed].msg_type
        sensor_id=config['sensors'][sensor_key]['sensor_id']

        print('\tGenerating rviz displays for sensor ' + sensor_key + ' with topic ' + topic + ' (' + sensor_id + ')')

        # if msg_type == 'sensor_msgs/CompressedImage' or \
        #         msg_type == 'sensor_msgs/Image':  # add displays for camera sensor
        #TODO check if depth should be here or not
        if sensor_id== 'rgb' or sensor_id=='depth':

            # Raw image
            rendered = env.get_template('/rviz/Image.rviz').render(c={'Name': sensor_key + '-Image',
                                                                      'Image_Topic': topic})
            displays.append(yaml.load(rendered, Loader=yaml.SafeLoader))

            # Camera
            rendered = env.get_template('/rviz/Camera.rviz').render(c={'Name': sensor_key + '-Camera',
                                                                       'Image_Topic': topic})
            displays.append(yaml.load(rendered, Loader=yaml.SafeLoader))

        # elif msg_type == 'sensor_msgs/LaserScan':
        elif sensor_id=='laserscan':
            # Raw data
            rendered = env.get_template('/rviz/LaserScan.rviz').render(c={'Name': sensor_key + '-LaserScan',
                                                                          'Topic': topic,
                                                                          'Color': color})
            displays.append(yaml.load(rendered, Loader=yaml.SafeLoader))

        # elif msg_type == 'sensor_msgs/PointCloud2':
        elif sensor_id=='lidar':
            # Raw data
            rendered = env.get_template('/rviz/PointCloud2.rviz').render(c={'Name': sensor_key + '-PointCloud2',
                                                                            'Topic': topic,
                                                                            'Color': color,
                                                                            'Style': 'Spheres',
                                                                            'Size__m_': 0.02,
                                                                            'Alpha': 1})
            displays.append(yaml.load(rendered, Loader=yaml.SafeLoader))

        else:
            print(Fore.YELLOW + 'Warning: Cannot generate rviz configuration for sensor ' + sensor_key + ' with topic '
                  + topic + ' (' + sensor_id + ')' + Style.RESET_ALL)

    rviz['Visualization Manager']['Displays'] = displays
    yaml.dump(rviz, open(package_path + '/rviz/' + rviz_set_initial_estimate, 'w'))

    # --------------------------------------------------------------------------
    # Create the rviz config file for the collect_data
    # --------------------------------------------------------------------------
    print('Setting up ' + rviz_collect_data + ' ...')
    rviz = yaml.load(open(rviz_file_template), Loader=yaml.SafeLoader)
    rviz['Visualization Manager']['Global Options']['Fixed Frame'] = config[
        'world_link']  # set fixed frame to world_link
    displays = deepcopy(core_displays)  # start with the core displays

    # Add interactive maker display to handle sensor manual labelling
    rendered = env.get_template('/rviz/InteractiveMarker.rviz').render(
        c={'Name': 'ManualDataLabeler-InteractiveMarkers',
           'Update_Topic': 'data_labeler/update'}
    )
    displays.append(yaml.load(rendered, Loader=yaml.SafeLoader))
    # TODO this will be the menu (only one)

    # Generate rviz displays according to the sensor types
    for idx, sensor_key in enumerate(config['sensors']):
        color = atom_core.drawing.colormapToRVizColor(cm_sensors[idx, :])
        topic = config['sensors'][sensor_key]['topic_name']
        topic_compressed = topic + '/compressed'
        # if topic in bag_topics:
        #     msg_type = bag_info[1][topic].msg_type
        # else:
        #     msg_type = bag_info[1][topic_compressed].msg_type
        sensor_id=config['sensors'][sensor_key]['sensor_id']

        print('\tGenerating rviz displays for sensor ' + sensor_key + ' with topic ' + topic + ' (' + sensor_id + ')')

        # if msg_type == 'sensor_msgs/CompressedImage' or msg_type == 'sensor_msgs/Image':  # displays for camera sensor
        #TODO check if depth should be here or separated
        if sensor_id=='rgb' or sensor_id=='depth':
            # Image
            rendered = env.get_template('/rviz/Image.rviz').render(c={'Name': sensor_key + '-Labels' + '-Image',
                                                                      'Image_Topic': topic + '/labeled'})
            displays.append(yaml.load(rendered, Loader=yaml.SafeLoader))

            # Camera
            rendered = env.get_template('/rviz/Camera.rviz').render(c={'Name': sensor_key + '-Camera',
                                                                       'Image_Topic': topic})
            displays.append(yaml.load(rendered, Loader=yaml.SafeLoader))

        # elif msg_type == 'sensor_msgs/LaserScan':
        elif sensor_id=='laserscan':
            rendered = env.get_template('/rviz/LaserScan.rviz').render(c={'Name': sensor_key + '-LaserScan',
                                                                          'Topic': topic,
                                                                          'Color': color})
            displays.append(yaml.load(rendered, Loader=yaml.SafeLoader))

            # Labels
            rendered = env.get_template('/rviz/PointCloud2.rviz').render(c={'Name': sensor_key + '-Labels-PointCloud2',
                                                                            'Topic': topic + '/labeled',
                                                                            'Color': color,
                                                                            'Color_Transformer': 'FlatColor',
                                                                            'Style': 'Spheres',
                                                                            'Size__m_': 0.2,
                                                                            'Alpha': 0.05})
            displays.append(yaml.load(rendered, Loader=yaml.SafeLoader))

            # # TODO Add markers to display data clusters

            rendered = env.get_template('/rviz/InteractiveMarker.rviz').render(
                c={'Name': sensor_key + '-ManualDataLabeler-InteractiveMarkers',
                   'Update_Topic': sensor_key + '/data_labeler/update'}
            )
            displays.append(yaml.load(rendered, Loader=yaml.SafeLoader))



        # elif msg_type == 'sensor_msgs/PointCloud2':
        elif sensor_id=='lidar':
            # Raw data
            rendered = env.get_template('/rviz/PointCloud2.rviz').render(c={'Name': sensor_key + '-PointCloud2',
                                                                            'Topic': topic,
                                                                            'Color': color,
                                                                            'Color_Transformer': 'AxisColor',
                                                                            'Axis': 'Z',
                                                                            'Style': 'Spheres',
                                                                            'Size__m_': 0.02,
                                                                            'Alpha': 1})
            displays.append(yaml.load(rendered, Loader=yaml.SafeLoader))

            # Labeled data
            rendered = env.get_template('/rviz/PointCloud2.rviz').render(c={'Name': sensor_key + '-Labels-PointCloud2',
                                                                            'Topic': topic + '/labeled',
                                                                            'Color': color,
                                                                            'Color_Transformer': 'FlatColor',
                                                                            'Style': 'Spheres',
                                                                            'Size__m_': 0.2,
                                                                            'Alpha': 0.05})
            displays.append(yaml.load(rendered, Loader=yaml.SafeLoader))

            # Interactive marker for the labeler
            rendered = env.get_template('/rviz/InteractiveMarker.rviz').render(
                c={'Name': sensor_key + '-ManualDataLabeler-InteractiveMarkers',
                   'Update_Topic': sensor_key + '/data_labeler/update'}
            )
            displays.append(yaml.load(rendered, Loader=yaml.SafeLoader))

        else:
            print(Fore.YELLOW + 'Warning: Cannot generate rviz configuration for sensor ' + sensor_key + ' with topic '
                  + topic + ' (' + sensor_id + ')' + Style.RESET_ALL)

    rviz['Visualization Manager']['Displays'] = displays
    yaml.dump(rviz, open(package_path + '/rviz/' + rviz_collect_data, 'w'))

    # --------------------------------------------------------------------------
    # Create the rviz config file for the calibrate
    # --------------------------------------------------------------------------
    print('Setting up ' + rviz_calibrate + ' ...')
    rviz = yaml.load(open(rviz_file_template), Loader=yaml.SafeLoader)
    rviz['Visualization Manager']['Global Options']['Fixed Frame'] = config[
        'world_link']  # set fixed frame to world_link
    displays = deepcopy(core_displays)  # start with the core displays
    displays.pop()  # remove the last item, which is the robot model

    # Add interactive maker display for showing robot meshes
    rendered = env.get_template('/rviz/MarkerArray.rviz').render(
        c={'Name': 'RobotMeshes-MarkerArray',
           'Marker_Topic': 'calibrate/robot_meshes'}
    )
    displays.append(yaml.load(rendered, Loader=yaml.SafeLoader))

    # Add a maker array display for showing the patterns
    rendered = env.get_template('/rviz/MarkerArray.rviz').render(
        c={'Name': 'Patterns-MarkerArray',
           'Marker_Topic': 'calibrate/patterns'}
    )
    displays.append(yaml.load(rendered, Loader=yaml.SafeLoader))

    # Add a maker array display for miscellaneous information
    rendered = env.get_template('/rviz/MarkerArray.rviz').render(
        c={'Name': 'Miscellaneous-MarkerArray',
           'Marker_Topic': 'calibrate/Miscellaneous'}
    )
    displays.append(yaml.load(rendered, Loader=yaml.SafeLoader))

    # Check if 2d lidars exist, if so add laser beams marker
    sensor_ids = []
    for idx, sensor_key in enumerate(config['sensors']):
        sensor_id = config['sensors'][sensor_key]['sensor_id']
        sensor_ids.append(sensor_id)

    if 'laserscan' in sensor_ids:  # we have 2D lidar data, add laser beams marker
        # Add interactive maker display for showing laser beams
        rendered = env.get_template('/rviz/MarkerArray.rviz').render(
            c={'Name': 'LaserBeams-MarkerArray',
               'Marker_Topic': 'calibrate/LaserBeams'}
        )
        displays.append(yaml.load(rendered, Loader=yaml.SafeLoader))

    # Generate rviz displays according to the sensor types
    for idx, sensor_key in enumerate(config['sensors']):
        color = atom_core.drawing.colormapToRVizColor(cm_sensors[idx, :])
        topic = config['sensors'][sensor_key]['topic_name']
        topic_compressed = topic + '/compressed'
        # if topic in bag_topics:
        #     msg_type = bag_info[1][topic].msg_type
        # else:
        #     msg_type = bag_info[1][topic_compressed].msg_type
        sensor_id = config['sensors'][sensor_key]['sensor_id']

        print('\tGenerating rviz displays for sensor ' + sensor_key + ' with topic ' + topic + ' (' + sensor_id + ')')
        #TODO check if depth should be here or separated
        if sensor_id == 'rgb' or sensor_id == 'depth':  # displays for camera sensor

            # Image
            rendered = env.get_template('/rviz/Image.rviz').render(c={'Name': sensor_key + '-Labels' + '-Image',
                                                                      'Image_Topic': 'calibrate/c0' + topic + '/labeled'})
            displays.append(yaml.load(rendered, Loader=yaml.SafeLoader))

        elif sensor_id == 'laserscan':
            # Labelled data
            rendered = env.get_template('/rviz/MarkerArray.rviz').render(c={'Name': sensor_key + '-LabeledData',
                                                                            'Marker_Topic': 'calibrate/labeled_data'}
                                                                         )
            displays.append(yaml.load(rendered, Loader=yaml.SafeLoader))

        elif sensor_id == 'lidar':
            # Labelled data
            rendered = env.get_template('/rviz/MarkerArray.rviz').render(c={'Name': sensor_key + '-LabeledData',
                                                                            'Marker_Topic': 'calibrate/labeled_data'}
                                                                         )
            displays.append(yaml.load(rendered, Loader=yaml.SafeLoader))

    rviz['Visualization Manager']['Displays'] = displays
    yaml.dump(rviz, open(package_path + '/rviz/' + rviz_calibrate, 'w'))

    # Print final report
    print(
        '\nCreated a calibration configuration summary. Use it to see if the calibration is well set up. Located at:\n'
        + package_path + '/calibration/summary.pdf')
    print('\nSuccessfully configured calibration package ' + Fore.BLUE + package_name + Style.RESET_ALL +
          '. You can use the launch files:')
    print(Fore.BLUE + 'roslaunch ' + package_name + ' ' + os.path.basename(playbag_launch_file) + Style.RESET_ALL)
    print(Fore.BLUE + 'roslaunch ' + package_name + ' ' + os.path.basename(set_initial_estimate_launch_file) +
          Style.RESET_ALL)
    print(Fore.BLUE + 'roslaunch ' + package_name + ' ' + os.path.basename(data_collection_launch_file) +
          Style.RESET_ALL)
    print(Fore.BLUE + 'roslaunch ' + package_name + ' ' + os.path.basename(calibrate_launch_file) + Style.RESET_ALL)
