#
#           █████╗ ████████╗ ██████╗ ███╗   ███╗
#          ██╔══██╗╚══██╔══╝██╔═══██╗████╗ ████║
#          ███████║   ██║   ██║   ██║██╔████╔██║
#          ██╔══██║   ██║   ██║   ██║██║╚██╔╝██║
#   __     ██║  ██║   ██║   ╚██████╔╝██║ ╚═╝ ██║    _
#  / _|    ╚═╝  ╚═╝   ╚═╝    ╚═════╝ ╚═╝     ╚═╝   | |
#  | |_ _ __ __ _ _ __ ___   _____      _____  _ __| | __
#  |  _| '__/ _` | '_ ` _ \ / _ \ \ /\ / / _ \| '__| |/ /
#  | | | | | (_| | | | | | |  __/\ V  V / (_) | |  |   <
#  |_| |_|  \__,_|_| |_| |_|\___| \_/\_/ \___/|_|  |_|\_\
#  https://github.com/lardemua/atom
# Auto-generated file on 01/12/2023 08:06:04

# This yaml file describes your calibration!


# Start by defining your robotic system.
# This is the URDF file (or xacro) that describes your robot.
# Every time a path to a file is requested you can use
#
#   - Absolute Path
#       Example 1: /home/user/ros_workspace/your_package/urdf/description.urdf.xacro
#       Example 2: file://home/user/ros_workspace/your_package/urdf/description.urdf.xacro
#
#   - Path Expansion
#       Example 1: ${HOME}/user/${YOUR_VARIABLE}/your_package/urdf/description.urdf.xacro
#       Example 2: ~/user/ros_workspace/your_package/urdf/description.urdf.xacro
#
#       NOTE: It is up to you to guarantee the environment variable exists.
#
#   - ROS Package Reference
#       Example: package://your_package/urdf/description.urdf.xacro
#
description_file: "package://eye_in_world_system_description/urdf/robot.urdf.xacro"

# The calibration framework requires a bagfile to extract the necessary data for the calibration.
bag_file: "$ROS_BAGS/eye_in_world_system/train.bag"

# You must define a frame of reference for the optimization process.
# It must exist in the transformation chains of all the sensors which are being calibrated.
world_link: "world"

# ATOM will calibrate the extrinsic parameters of your sensors.
# In this section you should discriminate the sensors that will be part of the calibrations.
sensors:
  # Each key will define a sensor and its name, which will be use throughout the calibration.
  # Each sensor definition must have the following properties:
  #       link:
  #           The frame of the sensor's data (i.e. the header.frame_id).
  #       parent_link:
  #           The parent link of the transformation (i.e. link) to be calibrated.
  #       child_link:
  #           This is the transformation (i.e. link) that we be optimized.
  #       topic_name:
  #           Name of the ROS topic that contains the data produced by this sensor.
  #           If you are calibrating an camera, you should use the raw image produced by the
  #           sensors. Additionally, it the topic is an image it will automatically use the
  #           respective `camera_info` topic.
  #       modality:
  #           Set this to identify the sensor modality. If this flag is not set, the sensor will be
  #           identified by the message type.
  #           Current options: lidar3d, rgb, depth, lidar2d
  #       throttle:
  #           Set throttle: desired_frame_rate. If you don't use throttle, do not enter a value, i.e. "throttle: "
  #
  # If you are using an image compressed topic such as:
  #   /world_camera/rgb/image_raw/compressed
  # you should not add the "compressed" part, use only:
  #   /world_camera/rgb/image_raw
  #

  rgb_world:
    link: "rgb_world_optical_frame"
    parent_link: "tripod_center_support"
    child_link: "rgb_world_link"
    topic_name: "/rgb_world/image_raw"
    modality: "rgb"
    throttle:

# ATOM will calibrate the extrinsic parameters of your links.
# In this section you should discriminate the additional transformations that will be part of the calibrations.
additional_tfs:
  # Each key will define a transformations and its name, which will be use throughout the calibration.
  # Each additional transformations definition must have the following properties:
  #
  #       parent_link:
  #           The parent link of the transformation (i.e. link) to be calibrated.
  #
  #       child_link:
  #           This is the transformation (i.e. link) that we be optimized.
  #
  # EXAMPLE:
  #base_footprint_to_base_link:
  #  parent_link: "base_footprint"
  #  child_link: "base_link"

# ATOM can also calibrate several parameters of your joints.
# In this section you should discriminate the joints that will be part of the calibrations.
# For each joint you must specify which parameters to optimize.
# The joint is identified by its name, consistent with the URDF description.
joints:
  # Each key will define a joint and its name, which will be use throughout the calibration.
  # Each joint definition must have the following properties:
  #
  #       params_to_calibrate:
  #           This is the list of parameters that will be optimized, from the urdf definition (http://wiki.ros.org/urdf/XML/joint):
  #           ['origin_x', 'origin_y', 'origin_z', 'origin_roll', 'origin_pitch', 'origin_yaw', 'position_bias']
  #
  # EXAMPLE:
  #head_pan_joint:
  #  params_to_calibrate: ['position_bias']

# The calibration requires a detectable pattern.
# This section describes the properties of the calibration pattern used in the calibration.
calibration_patterns:

  pattern_1:
    # The frame id (or link) of the pattern.
    # This link/transformation will be optimized.
    link: "pattern_link"

    # The parent frame id (or link) of the pattern.
    # For example, in hand-eye calibration the parent link
    # of the pattern can be the end-effector or the base of the arm
    parent_link: "flange"

    # Defines if the pattern link is the same in all collections (i.e. fixed=true),
    # or each collection will have its own estimate of the link transformation.
    # Note: if you plan to have the pattern fixed, while the moving the rigidly attached sensors,
    # this is equivalent to having the sensors fixed and the pattern moving, so you should use fixed=false.
    fixed: true

    # The type of pattern used for the calibration.
    # Supported pattern are:
    # - chessboard
    # - charuco
    pattern_type: "charuco"

    # If the pattern type is "charuco" you need to define
    # the aruco dictionary used by the pattern.
    # See https://docs.opencv.org/trunk/dc/df7/dictionary_8hpp.html
    dictionary: "DICT_4X4_100"

    # Mesh file (collada.dae or stl) for showing pattern on rviz. URI or regular path.
    # See: description_file
    mesh_file: "package://atom_worlds/pattern/models/charuco_200x200_4x4/charuco_200x200_4x4.dae"

    # The border width from the edge corner to the pattern physical edge.
    # Used for 3D sensors and lidars.
    # It can be a scalar (same border in x and y directions), or it can be {'x': ..., 'y': ,,,}
    border_size: { 'x': 0.02, 'y': 0.02 }

    # The number of corners the pattern has in the X and Y dimensions.
    # Note: The charuco detector uses the number of squares per dimension in its detector.
    # Internally we add a +1 to Y and X dimensions to account for that.
    # Therefore, the number of corners should be used even for the charuco pattern.
    dimension: { "x": 7, "y": 7 }

    # The length of the square edge.
    size: 0.02

    # The length of the charuco inner marker.
    inner_size: 0.015


# Miscellaneous configuration

# If your calibration problem is not fully constrained you should anchored one of the sensors.
# This makes it immovable during the optimization.
# This is typically referred to as gauge freedom.
anchored_sensor:

# Max time delta (in milliseconds) between sensor data messages when creating a collection.
max_duration_between_msgs: 1000

# This parameter is automatically filled by ATOM, please only change if you know what you are doing
package_name: "eye_in_world_system_calibration"

# Automatically filled. Do not touch unless you know what you are doing.
version: 2.0