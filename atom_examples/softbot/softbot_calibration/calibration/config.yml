#
#           █████╗ ████████╗ ██████╗ ███╗   ███╗
#          ██╔══██╗╚══██╔══╝██╔═══██╗████╗ ████║
#          ███████║   ██║   ██║   ██║██╔████╔██║
#          ██╔══██║   ██║   ██║   ██║██║╚██╔╝██║
#   __     ██║  ██║   ██║   ╚██████╔╝██║ ╚═╝ ██║    _
#  / _|    ╚═╝  ╚═╝   ╚═╝    ╚═════╝ ╚═╝     ╚═╝   | |
#  | |_ _ __ __ _ _ __ ___   _____      _____  _ __| | __
#  |  _| '__/ _` | '_ ` _ \ / _ \ \ /\ / / _ \| '__| |/ /
#  | | | | | (_| | | | | | |  __/\ V  V / (_) | |  |   <
#  |_| |_|  \__,_|_| |_| |_|\___| \_/\_/ \___/|_|  |_|\_\
#  https://github.com/lardemua/atom
# Auto-generated file on 14/03/2024 10:55:13

# This yaml file describes your calibration!


# Start by defining your robotic system.
# This is the URDF file (or xacro) that describes your robot.
# Every time a path to a file is requested you can use
#
#   - Absolute Path
#       Example 1: /home/user/ros_workspace/your_package/urdf/description.urdf.xacro
#       Example 2: file://home/user/ros_workspace/your_package/urdf/description.urdf.xacro
#
#   - Path Expansion
#       Example 1: ${HOME}/user/${YOUR_VARIABLE}/your_package/urdf/description.urdf.xacro
#       Example 2: ~/user/ros_workspace/your_package/urdf/description.urdf.xacro
#
#       NOTE: It is up to you to guarantee the environment variable exists.
#
#   - ROS Package Reference
#       Example: package://your_package/urdf/description.urdf.xacro
#
description_file: "package://softbot_description/urdf/softbot.urdf.xacro"

# The calibration framework requires a bagfile to extract the necessary data for the calibration.
# bag_file: "$ROS_BAGS/softbot/train.bag"
bag_file: "$ROS_BAGS/softbot/train.bag"

# You must define a frame of reference for the optimization process.
# It must exist in the transformation chains of all the sensors which are being calibrated.
world_link: "world"

# ATOM will calibrate the extrinsic parameters of your sensors.
# In this section you should discriminate the sensors that will be part of the calibrations.
sensors:
  # Each key will define a sensor and its name, which will be use throughout the calibration.
  # Each sensor definition must have the following properties:
  #       link:
  #           The frame of the sensor's data (i.e. the header.frame_id).
  #       parent_link:
  #           The parent link of the transformation (i.e. link) to be calibrated.
  #       child_link:
  #           This is the transformation (i.e. link) that we be optimized.
  #       topic_name:
  #           Name of the ROS topic that contains the data produced by this sensor.
  #           If you are calibrating an camera, you should use the raw image produced by the
  #           sensors. Additionally, it the topic is an image it will automatically use the
  #           respective `camera_info` topic.
  #       modality:
  #           Set this to identify the sensor modality. If this flag is not set, the sensor will be
  #           identified by the message type.
  #           Current options: lidar3d, rgb, depth, lidar2d
  #       throttle:
  #           Set throttle: desired_frame_rate. If you don't use throttle, do not enter a value, i.e. "throttle: "
  #
  # If you are using an image compressed topic such as:
  #   /world_camera/rgb/image_raw/compressed
  # you should not add the "compressed" part, use only:
  #   /world_camera/rgb/image_raw

  front_left_camera:
    link: "front_left_camera_rgb_optical_frame"
    parent_link: "front_left_camera_link"
    child_link: "front_left_camera_rgb_frame"
    topic_name: "/front_left_camera/rgb/image_raw"
    modality: "rgb"
    throttle: 10

  front_right_camera:
    link: "front_right_camera_rgb_optical_frame"
    parent_link: "front_right_camera_link"
    child_link: "front_right_camera_rgb_frame"
    topic_name: "/front_right_camera/rgb/image_raw"
    modality: "rgb"
    throttle: 10

  # Leaving this out for simplicity
  lidar3d:
    link: "lidar3d"
    parent_link: "lidar3d_plate_link"
    child_link: "lidar3d_base_link"
    topic_name: "/lidar3d/points"
    modality: "lidar3d"
    throttle: 10


# ATOM will calibrate the extrinsic parameters of your links.
# In this section you should discriminate the additional transformations that will be part of the calibrations.
additional_tfs:
  # Each key will define a transformations and its name, which will be use throughout the calibration.
  # Each additional transformations definition must have the following properties:
  #
  #       parent_link:
  #           The parent link of the transformation (i.e. link) to be calibrated.
  #
  #       child_link:
  #           This is the transformation (i.e. link) that we be optimized.
  #
  # EXAMPLE:
  #base_footprint_to_base_link:
  #  parent_link: "base_footprint"
  #  child_link: "base_link"


# ATOM can also calibrate several parameters of your joints.
# In this section you should discriminate the joints that will be part of the calibrations.
# For each joint you must specify which parameters to optimize.
# The joint is identified by its name, consistent with the URDF description.
joints:
  # Each key will define a joint and its name, which will be use throughout the calibration.
  # Each joint definition must have the following properties:
  #
  #       params_to_calibrate:
  #           This is the list of parameters that will be optimized, from the urdf definition (http://wiki.ros.org/urdf/XML/joint):
  #           ['origin_x', 'origin_y', 'origin_z', 'origin_roll', 'origin_pitch', 'origin_yaw']
  #
  # EXAMPLE:
  #head_pan_joint:
  #  params_to_calibrate: ['origin_yaw']

# The calibration requires a detectable pattern.
# This section describes the properties of the calibration pattern used in the calibration.
calibration_patterns:
  pattern_1:
    link: "pattern_link"
    parent_link: "world"
    fixed: True
    pattern_type: "charuco"
    dictionary: "DICT_5X5_100"
    mesh_file: "package://atom_worlds/pattern/models/charuco_800x600_5x5_100/charuco_800x600_5x5_100.dae"
    border_size: {'x': 0.04, 'y': 0.03}
    dimension: {'x': 11, 'y': 8}
    size: 0.06
    inner_size: 0.045

# Miscellaneous configuration

# If your calibration problem is not fully constrained you should anchored one of the sensors.
# This makes it immovable during the optimization.
# This is typically referred to as gauge freedom.
anchored_sensor: "front_left_camera"

# Max time delta (in milliseconds) between sensor data messages when creating a collection.
max_duration_between_msgs: 1000

# This parameter is automatically filled by ATOM, please only change if you know what you are doing
package_name: "softbot_calibration"

# Automatically filled. Do not touch unless you know what you are doing.
version: 3.0